#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass AEA
\begin_preamble
% Uncomment the line below if you wish to use the mathtime package:
%\usepackage[cmbold]{mathtime}

% The harvard package is required with bibtex
\usepackage[abbr]{harvard}

\draftSpacing{1.5}
\usepackage[strict]{changepage}
\end_preamble
\options reviewmode
\use_default_options false
\begin_modules
theorems-ams
\end_modules
\maintain_unincluded_children false
\language english
\language_package none
\inputencoding auto
\fontencoding default
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures false
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command bibtex
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 2
\tocdepth 2
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes true
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\author 357394701 "ppuetz"
\end_header

\begin_body

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
This is a template \SpecialChar LyX
 file for articles to be submitted to Journals of the
 American Economic Association (AEA).
 How to install the AEA \SpecialChar LaTeX
 class to your \SpecialChar LaTeX
 system is explained in 
\begin_inset Flex URL
status open

\begin_layout Plain Layout

https://wiki.lyx.org/Examples/AEA
\end_layout

\end_inset

.
\end_layout

\end_inset


\begin_inset Note Note
status collapsed

\begin_layout Enumerate
A journal name must be provided in 
\family sans
Document\SpecialChar menuseparator
Settings\SpecialChar menuseparator
Document Class\SpecialChar menuseparator
Class options\SpecialChar menuseparator
Custom
\family default
.
 Available options are:
\end_layout

\begin_deeper
\begin_layout Description
AER American Economic Review (default)
\end_layout

\begin_layout Description
PP Papers and Proceedings
\end_layout

\begin_layout Description
JEL Journal of Economic Literature
\end_layout

\begin_layout Description
JEP Journal of Economic Perspectives
\end_layout

\begin_layout Description
AEJ American Economics Journal
\end_layout

\begin_layout Plain Layout
If one of these is not explicitly given to the class option, the default
 AER is used.
\end_layout

\end_deeper
\begin_layout Enumerate
Also, choose typesetting mode as the class option.
 Available options are:
\end_layout

\begin_deeper
\begin_layout Description
finalmode to typeset the manuscript for submission for publication
\end_layout

\begin_layout Description
reviewmode to typeset a blind review copy
\end_layout

\begin_layout Description
draftmode to typeset a draft copy with 1.5-line spacing (or your own choice
 of spacing).
\end_layout

\end_deeper
\begin_layout Enumerate
If your system has the 
\family sans
mathtime
\family default
 package installed, uncomment the line about mathtime
\family typewriter
 
\family default
in 
\family sans
Document\SpecialChar menuseparator
Settings\SpecialChar menuseparator
\SpecialChar LaTeX
 Preamble
\family default
.
\end_layout

\begin_layout Enumerate
Set 
\family sans
\SpecialChar LaTeX
 font encoding
\family default
 to 
\begin_inset Quotes eld
\end_inset

None (no fontenc)
\begin_inset Quotes erd
\end_inset

 in menu 
\family sans
Document\SpecialChar menuseparator
Settings\SpecialChar menuseparator
Fonts
\family default
.
 (Because the default encoding 
\begin_inset Quotes eld
\end_inset

T1
\begin_inset Quotes erd
\end_inset

 may cause font problems in \SpecialChar LaTeX
 export.)
\end_layout

\begin_layout Enumerate
When you finalize your manuscript for submission, clean up unnecessary preambles
 in the exported \SpecialChar LaTeX
 file.
 You need to minimize the usage of packages.
\end_layout

\end_inset


\end_layout

\begin_layout Title
Methods Matter: p-Hacking and Publication Bias in Causal Analysis in Economics:
 Comment
\end_layout

\begin_layout Date
November, 2021
\end_layout

\begin_layout Author
Sebastian Kranz
\begin_inset Foot
status open

\begin_layout Plain Layout
Ulm University, Department of Mathematics and Economics, Helmholtzstr.
 18, D-89081 Ulm, Germany, sebastian.kranz@uni-ulm.de
\end_layout

\end_inset


\begin_inset space ~
\end_inset

 and Peter Pütz
\begin_inset Foot
status open

\begin_layout Plain Layout
Bielefeld University, Faculty of Business Administration and Economics,
 Universitätsstr.
 25, D-33615 Bielefeld, Germany, peter.puetz@uni-bielefeld.de
\end_layout

\end_inset


\end_layout

\begin_layout JEL
A14, C12, C52
\end_layout

\begin_layout Abstract
Brodeur et al.
 (2020) study hypothesis tests from economic articles and find evidence
 for p-hacking and publication bias, in particular for IV and DID studies.
 When adjusting for rounding errors in reported estimates and standard errors,
 statistical evidence for p-hacking from randomization tests and caliper
 tests at the 5% significance threshold vanishes for DID studies but remains
 for IV studies.
 In addition, BCH derive latent distributions of z-statistics absent publication
 bias using two different approaches.
 We establish for each approach a result that challenges its applicability.
\end_layout

\begin_layout Standard
Abel Brodeur, Nikolai Cook, and Anthony Heyes (2020), henceforth BCH, have
 collected a large, very insightful data set of hypothesis tests from 25
 economic journals.
 They compare articles that employ different empirical strategies to estimate
 causal effects and find evidence for p-hacking or publication bias overall
 and in particular for results relying on instrumental variables (IV) and
 to a smaller extent for difference-in-differences (DID) estimates.
\end_layout

\begin_layout Standard
We show that rounding errors in the reported coefficients and standard errors
 cause bunching of computed z-statistics, in particular at exactly 
\begin_inset Formula $z=2$
\end_inset

.
 When adjusting for this rounding problem, evidence for p-hacking in the
 data set substantially weakens.
 Replicating BCH's randomization and caliper tests at the 5% significance
 threshold, evidence only remains for IV.
 That being said, our adjustment has only little impact at the 10% significance
 threshold and on the kernel density estimates of z-statistics; BCH's correspond
ing insights are not substantially changed.
\end_layout

\begin_layout Standard
Finally, we note two issues unrelated to rounding.
 BCH use two different approaches to recover the latent distribution of
 z-statistics absent publication bias and p-hacking.
 We prove that the first approach, based on matching probability masses
 in the tails, generally fails to recover the true latent distribution.
 For the second approach, based on Andrews and Kasy (2019), a crucial independen
ce assumption is violated in BCH's data set.
 More details and additional analyses can be found in an extended working
 paper version (Kranz and Pütz, 2021, henceforth KP).
\end_layout

\begin_layout Section
The rounding problem
\end_layout

\begin_layout Standard
BCH have collected data for more than 21,000 hypothesis tests.
 For most tests (90.2%) the reported coefficient 
\begin_inset Formula $\mu$
\end_inset

 and its standard error 
\begin_inset Formula $\sigma$
\end_inset

 are collected and the (absolute) z-statistic 
\begin_inset Formula $z=abs(\mu)/\sigma$
\end_inset

 is computed from these values.
 For the remaining tests, the z-statistic was derived from a reported t-statisti
c (5.0%), p-value (4.7%) or confidence interval (0.1%).
\begin_inset Foot
status open

\begin_layout Plain Layout
An initial version of our comment detected that BCH's conversion from p-values
 into z-statistics wrongly assumed that all p-values correspond to one-sided
 tests.
 Brodeur et al.
 corrected this problem and also detected some smaller typos when converting
 the raw data.
 They kindly provided us with a corrected version of the data set and also
 made it publicly available.
 We use that updated data set for all our analyses in this comment.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
BCH's main statistical analyses focus on the 5% significance threshold.
 For their randomization tests, they assume that absent p-hacking or publication
 bias, the distribution of z-statistics would be continuous and differentiable
 so that in a sufficient small window 
\begin_inset Formula $[1.96-h,1.96+h]$
\end_inset

 around the 5% significance threshold, there should be roughly equally many
 significant results with 
\begin_inset Formula $z\ge1.96$
\end_inset

 as insignificant results with 
\begin_inset Formula $z<1.96$
\end_inset

.
\begin_inset Note Note
status open

\begin_layout Plain Layout
\begin_inset Foot
status open

\begin_layout Plain Layout
Ideally, one would use observation-specific thresholds that refer to the
 t-distribution and take into account the degrees of freedom instead of
 using the normal approximation.
 Pütz and Bruns (2020) show that low degrees of freedom are regularly encountere
d in economic articles.
 One important reason is the frequent use of clustered standard errors.
 In particular due to clustered standard errors, it is often not possible
 to collect the correct degrees of freedom from the information given in
 regression tables.
\end_layout

\end_inset


\end_layout

\end_inset

 They then compare the shares of significant and insignificant tests for
 a grid of window half-widths 
\begin_inset Formula $h\in\{0.05,0.075,0.1,0.2,0.3,0.4,0.5\}$
\end_inset

.
 The left panel of Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Share-of-significant"
plural "false"
caps "false"
noprefix "false"

\end_inset

 shows the corresponding shares of z-statistics above 1.96 for all window
 half-widths on a fine grid between 0.01 and 0.5 using the pooled data.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../Results/share_of_significant_tests-1.pdf
	scale 95

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Share-of-significant"

\end_inset

Share of significant results for different window half-widths
\end_layout

\end_inset


\end_layout

\begin_layout Figure Notes
The left panel corresponds to the case of no adjustment for rounding errors
 as in BCH.
 The right panel shows results with our adjustment that omits all observations
 whose reported standard error has a significand below 37.
 The shaded areas indicate 95% confidence intervals based on binomial tests.
 The gray vertical lines indicate the window half-widths that BCH studied.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
For window half-widths below 0.04, less than 50% of z-statistics are above
 the threshold of 1.96.
 But there is a massive, discontinuous increase of significant z-statistics
 once the window half-width exceeds 0.04.
 This jump has not been discussed by BCH whose smallest considered window
 half-width of 
\begin_inset Formula $h=0.05$
\end_inset

 is already on the right-hand side of this discontinuity.
\end_layout

\begin_layout Standard
The discontinuity occurs because the data set contains 260 z-statistics
 with a value of exactly 2.
 All these observations are counted as significant and thus cause the jump
 in the share of significant tests once 
\begin_inset Formula $1.96+h$
\end_inset

 reaches 2.
 These 260 observations constitute 37.9% of the total observations in the
 smallest window analyzed by BCH.
 The left panel of Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Number-of-included"
plural "false"
caps "false"
noprefix "false"

\end_inset

 shows the number of observations included for each window half-width and
 verifies the substantial jump at 
\begin_inset Formula $h=0.04$
\end_inset

.
 The right panels of Figure 1 and Figure 2 present adjusted results and
 are discussed in the next section.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../Results/number_of_included_observations-1.pdf
	scale 95

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Number-of-included"

\end_inset

Number of included observations for different window half-widths.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Rounding errors are likely the most important reason for the bunching of
 z-statistics at exactly 
\begin_inset Formula $z=2$
\end_inset

.
 68.6% of observations with a z-statistic of exactly 2 have just a single
 significant digit for the standard error and 97.7% have at most two significant
 digits.
 For the remaining observations these shares are just 17.2% and 59.8%, respectivel
y.
\end_layout

\begin_layout Standard
If the coefficients and standard errors were reported with more significant
 digits, the computed z-statistic could well have been smaller than 1.96.
 For example, assume the reported standard error is 
\begin_inset Formula $\sigma=0.02$
\end_inset

.
 Then this observation has a computed z-statistic of exactly 
\begin_inset Formula $z=2$
\end_inset

 if the reported coefficient is also rounded to one significant digit and
 given by 
\begin_inset Formula $\mu=0.04$
\end_inset

.
 If one computed the z-statistic using the original non-rounded values,
 it may range from an insignificant lower bound of 
\begin_inset Formula $z=1.4$
\end_inset

 (i.e.
\begin_inset space ~
\end_inset


\begin_inset Formula $0.035/0.025$
\end_inset

) to a highly significant upper bound of 
\begin_inset Formula $z=3$
\end_inset

 (i.e.
\begin_inset space ~
\end_inset


\begin_inset Formula $0.045/0.015$
\end_inset

).
\begin_inset Foot
status open

\begin_layout Plain Layout

\change_inserted 357394701 1635919023
\begin_inset CommandInset label
LatexCommand label
name "fn:Replying-to-an"

\end_inset


\change_unchanged
Replying to an initial version of our comment, Brodeur et al.
 looked at the DID articles with the largest number of tests with 
\begin_inset Formula $z=2$
\end_inset

 and collected the reported significance stars.
 From the collected 43 tests 5 had no stars, 14 had one star, 21 had two
 stars and 3 had three stars.
\end_layout

\end_inset


\end_layout

\begin_layout Section
Adjusting for the rounding problem
\end_layout

\begin_layout Standard
There are different approaches to adjust for the rounding problem.
 Brodeur et al.
 (2016) and Bruns et al.
 (2019) deround reported coefficients and standard errors by assuming that
 missing digits are drawn from a uniform distribution.
 While intuitively appealing, we show in a Monte-Carlo study in the online
 appendix that this uniform derounding approach may induce an attenuation
 bias in the randomization tests.
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
The Monte-Carlo study also confirms that without any rounding adjustment
 there is a substantial upward bias due to the bunching at 
\begin_inset Formula $z=2$
\end_inset

.
\end_layout

\end_inset

 Furthermore, it is not clear how to compute valid confidence intervals
 for the uniform derounding approach.
 To overcome these issues, we implement an alternative approach that omits
 observations that are too coarsely rounded.
 Concretely, we omit all observations whose standard error has a significand
 
\begin_inset Formula $s$
\end_inset

 below a threshold 
\begin_inset Formula $\bar{s}=37$
\end_inset

.
 The significand consists of the significant digit(s) written as an integer,
 e.g.
\begin_inset space ~
\end_inset

for 
\begin_inset Formula $\sigma=0.012$
\end_inset

, the significand is 
\begin_inset Formula $s=12$
\end_inset

.
\end_layout

\begin_layout Standard
Assume the true z-statistic 
\begin_inset Formula $\tilde{z}$
\end_inset

 follows a distribution function 
\begin_inset Formula $F(\tilde{z})$
\end_inset

 and let 
\begin_inset Formula $F(\tilde{z}\vert s\geq\bar{s})$
\end_inset

 be the distribution function of the 
\begin_inset Formula $z$
\end_inset

-statistics that we select.
\end_layout

\begin_layout Standard
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard

\series bold
Assumption 1.

\series default
\shape italic
 Our selection does not affect the distribution of true z-statistics: 
\begin_inset Formula $F(\tilde{z})=F(\tilde{z}\vert s\geq\bar{s}).$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard
A model that satisfies Assumption 1 is the following.
 The true z-statistic 
\begin_inset Formula $\tilde{z}$
\end_inset

 is independently distributed from the true standard error 
\begin_inset Formula $\tilde{\sigma}$
\end_inset

 and the number of reported decimal places 
\begin_inset Formula $d$
\end_inset

.
 The true coefficient is given by 
\begin_inset Formula $\tilde{\mu}=\tilde{z}\cdot\tilde{\sigma}$
\end_inset

.
 The reported coefficients 
\begin_inset Formula $\mu$
\end_inset

 and 
\begin_inset Formula $\sigma$
\end_inset

 are derived by rounding 
\begin_inset Formula $\tilde{\mu}$
\end_inset

 and 
\begin_inset Formula $\tilde{\sigma}$
\end_inset

 to 
\begin_inset Formula $d$
\end_inset

 decimal places and the reported z-statistic is 
\begin_inset Formula $z=\mu/\sigma$
\end_inset

.
\end_layout

\begin_layout Standard
Assumption 1 cannot be directly tested as the true z-statistics 
\begin_inset Formula $\tilde{z}$
\end_inset

 are unobserved.
 However, it suggests that for the reported z-statistics the distribution
 of the selected sample should look similar to that of the full sample,
 except for the bunching points.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:excess-tests"

\end_inset

 (further below) shows that indeed the kernel density estimates of the two
 samples look very similar.
 In a similar spirit, Assumption 1 suggests that reported z-statistics and
 reported standard errors should not exhibit a strong correlation.
 Indeed, we find a correlation of only 
\begin_inset Formula $-0.0002$
\end_inset

 with 95% confidence interval 
\begin_inset Formula $[-0.0138,0.0134]$
\end_inset

.
 One plausible reason for this low correlation is that the main source of
 variation in 
\begin_inset Formula $\sigma$
\end_inset

 (and 
\begin_inset Formula $\mu$
\end_inset

) is different scaling of explanatory and dependent variables across the
 regressions, which seems uncorrelated with the true z-statistic.
 Also the empirical correlation between a dummy indicating whether an observatio
n is omitted and the reported z-statistic is only 
\begin_inset Formula $-0.005$
\end_inset

 with 95% confidence interval 
\begin_inset Formula $[-0.019,0.008]$
\end_inset

.
\end_layout

\begin_layout Standard
One concern could be that coarse rounding is used as a form of p-hacking
 in order to wrongly suggest z-statistics that pass the significant threshold.
 This would suggest that we observe more coarse rounding for z-statistics
 that are close to the 5% (or 10%) significance threshold where p-hacking
 concerns seem most relevant.
 However, Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:excess-tests"

\end_inset

 shows that in that range the selected subsample without coarse rounding
 even has a slightly larger density than the complete sample.
\begin_inset Note Note
status open

\begin_layout Plain Layout
Ist Figure 6 korrekt? Bei RDD z.B.
 sieht es so aus als hätte die schwarze Kurve mehr Fläche unter der Kurve.
\end_layout

\end_inset

 Also recall Footnote 
\begin_inset CommandInset ref
LatexCommand ref
reference "fn:Replying-to-an"
plural "false"
caps "false"
noprefix "false"

\end_inset

, which shows that a substantial fraction of a selection of DID tests with
 
\begin_inset Formula $z=2$
\end_inset

 indeed reported significance levels above 5%, i.e.
 for these tests coarse rounding was not used to wrongfully suggest a 5%
 significance level.
\begin_inset Note Note
status open

\begin_layout Plain Layout
Pütz and Bruns (2021) coded significance levels for a dataset including
 30,993 statistical tests from top economics journals.
 They found that 28% of 314 tests with 
\begin_inset Formula $z=2$
\end_inset

 reported significance levels above 5%.
 Among these 314 tests, for 266 
\begin_inset Formula $s<37$
\end_inset

 holds and would be dropped by our omission approach.
 Out of these tests, 32% reported significance levels above 5%.
 Applying the median uniform derounding approach with 10,000 repitions to
 the 266 tests with 
\begin_inset Formula $s<37$
\end_inset

 , i.e.
 assuming no strategic rounding, the median of the share of resulting z-statisti
cs below 1.96 was 37%.
 These results provide a further indication for the assumption that rounding
 as a form of p-hacking is unlikely to be a relevant issue in empirical
 economics.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Our omission approach requires to specify a concrete threshold 
\begin_inset Formula $\bar{s}$
\end_inset

.
 A larger threshold 
\begin_inset Formula $\bar{s}$
\end_inset

 has the drawback to reduce statistical power by omitting more observations,
 but has the advantage to reduce the impact of rounding errors.
\begin_inset Foot
status open

\begin_layout Plain Layout
See the online appendix for a quantification of the power loss from our
 adjustment method.
\end_layout

\end_inset

 The latter effect is formalized by
\end_layout

\begin_layout Standard
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard

\series bold
Lemma 1.

\series default
 
\shape italic
The true and reported z-statistics 
\begin_inset Formula $\tilde{z}$
\end_inset

 and 
\begin_inset Formula $z$
\end_inset

 are guaranteed not to lie on opposite sides of an arbitrary threshold 
\begin_inset Formula $\tau$
\end_inset

 if the significand 
\begin_inset Formula $s$
\end_inset

 of the standard error satisfies
\begin_inset Formula 
\begin{equation}
s\geq\frac{1+\tau}{2\vert z-\tau\vert}.\label{eq:s_thresh-1}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard
The proof is in the online appendix.
 We say an observation is 
\shape italic
misclassified 
\shape default
if its reported z-statistic 
\begin_inset Formula $z$
\end_inset

 and true z-statistic 
\begin_inset Formula $\tilde{z}$
\end_inset

 lie on opposite sides of the significance threshold 
\begin_inset Formula $\tau=1.96$
\end_inset

.
 Lemma 1 implies that 
\begin_inset Formula $\bar{s}=37$
\end_inset

 is the smallest omission threshold guaranteeing that no observation with
 
\begin_inset Formula $z=2$
\end_inset

 is misclassified.
 We will use this threshold in our analysis.
 In total, there are 160 distinct z-statistics with more than 10 observations
 each.
 But among them 
\begin_inset Formula $z=2$
\end_inset

 is closest to the significance threshold 
\begin_inset Formula $\tau=1.96$
\end_inset

.
 Lemma 1 implies that no remaining observation at one of these bunching
 values is misclassified for 
\begin_inset Formula $\bar{s}=37$
\end_inset

.
\end_layout

\begin_layout Standard
Besides misclassification, rounding errors can also cause an observation
 to be wrongly included in a window 
\begin_inset Formula $[1.96-h,1.96+h]$
\end_inset

 if 
\begin_inset Formula $z$
\end_inset

 is inside the window but 
\begin_inset Formula $\tilde{z}$
\end_inset

 outside, or wrongly excluded the other way round.
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
Note that collecting data on the reported significance levels for each observati
on (if available) could be another way to solve the misclassification problem
 arising from rounding errors.
 But it would not solve the problems of potentially wrong inclusion or exclusion.
\end_layout

\end_inset

 Lemma 1 implies that our omission threshold 
\begin_inset Formula $\bar{s}=37$
\end_inset

 guarantees that no remaining observation with 
\begin_inset Formula $z=2$
\end_inset

 is wrongly included or excluded from windows with half-width 
\begin_inset Formula $h\geq0.08$
\end_inset

.
 Thus, only for the two smallest window half-widths considered by BCH, we
 cannot rule out that after our adjustment some observations with 
\begin_inset Formula $z=2$
\end_inset

 are still wrongly included in that window.
 Of course, our adjustment cannot guarantee a zero risk of misclassification,
 wrong inclusion or exclusion of observations for all reported values of
 
\begin_inset Formula $z$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
\begin_inset Float figure
placement h
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../Results/misclass-1.pdf

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:misclass"

\end_inset

Share of observations at risk of misclassification, wrong inclusion or exclusion
 in a window with half-width 
\begin_inset Formula $h=0.1$
\end_inset

.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:misclass"

\end_inset

 illustrates the risks for a window with half-width 
\begin_inset Formula $h=0.1$
\end_inset

.
 It shows, as a function of the omission threshold for the significand 
\begin_inset Formula $s$
\end_inset

, the share of observations relative to the total observations in the window
 which are at risk of being misclassified or wrongly included, as well as
 the relative number of observations outside the window at risk of being
 wrongly excluded.
 Importantly, for very low omission thresholds, we have an asymmetry: More
 observations with reported 
\begin_inset Formula $z\geq1.96$
\end_inset

 are at risk of being misclassified or wrongly included, which is driven
 to a large extent by the observations with 
\begin_inset Formula $z=2$
\end_inset

.
 Likewise, more observations with 
\begin_inset Formula $z<1.96$
\end_inset

 are at risk to be wrongly excluded.
 While there is still error potential for our threshold of 
\begin_inset Formula $s=37$
\end_inset

 (gray vertical line), there are similarly many observations at risk on
 both sides of the 
\begin_inset Formula $z=1.96$
\end_inset

 threshold.
\end_layout

\end_inset

For generating the right-hand panel of Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Share-of-significant"
plural "false"
caps "false"
noprefix "false"

\end_inset

, we have applied our adjustment procedure to the pooled data.
 The discontinuity at 
\begin_inset Formula $h=0.04$
\end_inset

 vanishes and no clear evidence for p-hacking or publication bias remains.
 The shares of significant z-statistics decrease for all window half-widths,
 they are mostly close to 50% and the confidence intervals always include
 the 50% level.
 Overall, our adjustment omits 37.9% of observations, but it omits 87.3% of
 observations with 
\begin_inset Formula $z=2$
\end_inset

 and 81.1% of other observations that have a z-statistic with at least 10
 observations each.
 The right-hand panel of Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Number-of-included"
plural "false"
caps "false"
noprefix "false"

\end_inset

 shows that with our sample selection, the number of included observations
 increases smoothly with growing window half-width 
\begin_inset Formula $h$
\end_inset

 without any visible jumps.
\end_layout

\begin_layout Section
Replication results
\end_layout

\begin_layout Standard
In this section we replicate the main analyses from BCH using our adjusted
 data set.
 BCH compare the evidence for p-hacking and publication bias between four
 different identification strategies: difference-in-differences (DID), instrumen
tal variable (IV), randomized experiment (RCT) and regression discontinuity
 design (RDD).
 The share of observations with a z-statistic of exactly 2 differs substantially
 between the sub-samples corresponding to the different identification strategie
s.
 In the smallest window studied by BCH, it ranges from only 16.6% for IV
 to 50.0% for DID.
 Correspondingly, adjusting for rounding errors affects in particular the
 DID results.
\end_layout

\begin_layout Subsection
Randomization tests
\end_layout

\begin_layout Standard
Table 3 in BCH shows the share of observations with 
\begin_inset Formula $z\geq1.96$
\end_inset

 in the window 
\begin_inset Formula $[1.96-h;1.96+h]$
\end_inset

 for different window sizes 
\begin_inset Formula $h$
\end_inset

 and different identification strategies.
 It also presents the p-value of a one-sided binomial test with the null
 hypothesis that this share does not exceed 50%.
\end_layout

\begin_layout Standard
\begin_inset Float table
placement h
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:binom"

\end_inset

Randomization tests
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
footnotesize
\end_layout

\begin_layout Plain Layout


\backslash
input{../Results/binom05_aer_omit.tex}
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:binom"

\end_inset

 shows the results using our adjustment.
 We find the largest difference to BCH for DID.
 While in BCH the share of significant tests varied between 53.0% and 70.7%
 (with p-values between 0.000 and 0.030), with our adjustment for rounding
 the share ranges between 44.6% and 50.7% (with p-values between 0.367 and
 0.904).
 For RDD and RCT, the share of significant tests is never significantly
 above 50% with adjustment while BCH found significant results for smaller
 window sizes.
 For IV, the adjustment changes little compared to BCH in terms of magnitude
 and the p-values (ranging from 0.001 to 0.056 with our adjustment).
\begin_inset Note Note
status open

\begin_layout Plain Layout
sollten wir die spalten rdd und rct tauschen, um es enfacher vergleichbar
 mit BCH zu machen?
\end_layout

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
The power-loss induced by the omission approach can be quantified by computing
 the standard errors of the means and comparing them to their analogs in
 BCH's Table 3.
 For the smallest window size, omitting coarsely rounded values leads to
 an increase of the standard error of the mean between 12% (IV) and 57%
 (DID), while the increase for the largest window size varies between 12%
 (IV) and 28% (RDD).
\end_layout

\end_inset


\end_layout

\begin_layout Standard
At the 10% threshold results are closer to BCH (see online appendix Table
 A3).
 For larger window sizes we still find significant results for DID.
 As Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:dist-method"

\end_inset

 shows, densities of z-statistics generally slope upwards around this threshold.
 In contrast, at the 1% threshold, the densities slope downwards and the
 share of tests with 
\begin_inset Formula $z\geq2.576$
\end_inset

 is significantly below 50% for many window half-widths (see online appendix
 Table A4).
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Note that corresponding with the increasing slopes of the densities around
 the 10% significance threshold, we show in the online appendix that indeed
 all randomization tests for IV are significant.
 For DID, we find significant results for sufficiently large window sizes
 and to a smaller extent even for RCT.
 However, at the 1% threshold, the densities slope downwards and the share
 of tests with 
\begin_inset Formula $z\geq2.576$
\end_inset

 is significantly below 50% for many window half-widths.
 [TO DO: Discuss 10% results]
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Caliper tests
\end_layout

\begin_layout Standard
BCH proceed their analyses with so-called caliper tests.
 Again, all observations with z-statistics in a specified window around
 the 
\begin_inset Formula $z=1.96$
\end_inset

 threshold are considered and probit regressions of the following form are
 performed:
\begin_inset Formula 
\[
Pr(Significant_{i}=1)=\Phi(\alpha+X_{i}'\boldsymbol{\delta}+\gamma DID_{i}+\lambda IV_{i}+\phi RDD_{i}).
\]

\end_inset


\begin_inset Formula $Significant_{i}$
\end_inset

 is a dummy variable indicating whether 
\begin_inset Formula $z_{i}\geq1.96$
\end_inset

 and 
\begin_inset Formula $X_{i}$
\end_inset

 is a vector of control variables, including author and article characteristics.
 Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:caliper"
plural "false"
caps "false"
noprefix "false"

\end_inset

 shows our replication results of the caliper tests using the adjusted data
 set.
\end_layout

\begin_layout Standard
\begin_inset Float table
placement h
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:caliper"

\end_inset

Caliper tests
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{adjustwidth}{-0cm}{-0cm}
\end_layout

\begin_layout Plain Layout


\backslash
small
\end_layout

\begin_layout Plain Layout


\backslash
input{../Results/caliper_table_sign_5pct.tex}
\end_layout

\begin_layout Plain Layout


\backslash
end{adjustwidth}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Table Notes
The shown coefficients are marginal effects at the means.
 For dummy variables we measure the effect of a change from 0 to 1.
 Standard errors in parentheses are clustered at article level.
 Observations are weighted by the inverse of the number of tests conducted
 in the same article.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
For example, the first column shows that in the window 
\begin_inset Formula $[1.96-0.5;1.96+0.5]$
\end_inset

 tests from IV studies are 10.1 percentage points more likely to be significant
 than tests from RCT studies of which 46.9% are significant in that window.
 Overall, the estimates for IV are very similar to those of BCH and remain
 significant when performing our adjustment for rounding errors.
 In contrast, effect sizes for DID substantially reduce with our adjustment
 and, contrasting the findings of BCH, are not statistically significant
 in any specification.
 So after adjustment for rounding errors, the caliper tests provide no more
 evidence for p-hacking of DID studies at the 5% threshold than the randomizatio
n tests.
 Results at the 10% and 1% threshold are shown in Tables A5 and A6 in the
 online appendix and are closer to BCH's original findings.
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
In the online appendix, we show that for the 10% significance threshold
 applying our omission approach generally leads to larger effects for DID
 and IV compared to BCH.
 On the other hand, our rounding adjustment barely changes the insignificant
 results found by BCH when applying the 1% significance threshold (see also
 the online appendix).
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Distribution of z-statistics
\end_layout

\begin_layout Standard
In this subsection we show the empirical distribution of z-statistics with
 our rounding adjustment for different subsamples analyzed by BCH.
 In general, the kernel density estimates are quite similar to BCH's and
 show even a slightly more pronounced second hump.
\begin_inset Foot
status open

\begin_layout Plain Layout
Note that the default kernel density is biased towards zero at the left
 margin, but we use that estimator for better comparison with BCH.
 See online appendix Figure A3 for a version of Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:excess-tests"

\end_inset

 with bias-corrected density estimator.
\end_layout

\end_inset

 The main effect of the adjustment procedure is that the histograms exhibit
 less bunching at 
\begin_inset Formula $z=2$
\end_inset

 and at other bunching points such as 
\begin_inset Formula $z=1$
\end_inset

.
\end_layout

\begin_layout Standard
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:dist-z"

\end_inset

 shows the empirical distribution of z-statistics overall as well as the
 respective distributions for the Top 5 and non-Top 5 journals with adjustment
 for the rounding problem.
 For Top 5 articles no bunching right of the 5% significance level is observable
 anymore, but the density still increases strongly right of the 10% threshold.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement !h
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../Results/figure1a_BCH_omission.pdf
	scale 47

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../Results/figure1b_BCH_omission.pdf
	scale 47
	rotateOrigin center

\end_inset


\begin_inset Graphics
	filename ../Results/figure1c_BCH_omission.pdf
	scale 47

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:dist-z"

\end_inset


\begin_inset Formula $z$
\end_inset

-statistics in 25 top economics journals
\end_layout

\end_inset


\end_layout

\begin_layout Figure Notes
Replicates Figure 1 in BCH.
 The top panel presents the distribution of all test statistics for 
\begin_inset Formula $z∈[0,10]$
\end_inset

.
 The bottom panels show test statistics from the Top 5 journals (
\shape italic
American Economic Review, Econometrica, Journal of Political Economy, Quarterly
 Journal of Economics, 
\shape default
and
\shape italic
 Review of Economic Studies
\shape default
, left panel) and the remaining sample (right panel).
 The vertical lines indicate the critical z-statistics at the 10%, 5% and
 1% significance levels.
 The histograms have bin size 0.1.
 The black lines are density estimates based on a Epanechnikov kernel with
 bandwidth 0.1.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
With respect to the next subsection, note that the default kernel density
 estimator (dark gray line on left) used by BCH is biased towards zero at
 the left margin.
 We use a corrected density estimator (black line) that makes the shape
 look less like a camel because the first hump is rather at zero than at
 small positive z-statistics.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:dist-method"
plural "false"
caps "false"
noprefix "false"

\end_inset

 compares the densities of z-statistic for the four strategies of causal
 identification.
 In comparison to BCH, a more pronounced hump of the density estimator around
 
\begin_inset Formula $z=2$
\end_inset

 can especially be observed for DID, while at the same time bunching at
 exactly 
\begin_inset Formula $z=2$
\end_inset

 is substantially reduced for all methods.
\begin_inset Float figure
placement h
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../Results/figure2_BCH_omission.pdf
	scale 125

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:dist-method"

\end_inset


\begin_inset Formula $z$
\end_inset

-statistics by method
\end_layout

\end_inset


\end_layout

\begin_layout Figure Notes
Replicates Figure 2 in BCH.
 The figure presents the distributions of statistics for 
\begin_inset Formula $z∈[0,10]$
\end_inset

 for each of the four idenfication methods: difference- in-differences (DID),
 instrumental variables (IV), randomized control trial (RCT), and regression
 discontinuity design (RDD).
 The vertical lines indicate the the critical z-statistics at the 10%, 5%
 and 1% significance levels.
 The histograms have bin size 0.1.
 The black lines are density estimates based on a Epanechnikov kernel with
 bandwidth 0.1.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:dist-over-time"
plural "false"
caps "false"
noprefix "false"

\end_inset

 compares the distribution of z-statistics over time for three top journals
 (upper panels) and the Top 25 journals (lower panels).
 Omitting too coarsely rounded values does not change the main message of
 BCH's Figure 3, namely that the distributions for both journal groups do
 not change remarkably over time.
\begin_inset Float figure
placement h
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../Results/figure3_BCH_omission.pdf
	scale 125

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:dist-over-time"

\end_inset


\begin_inset Formula $z$
\end_inset

-statistics in 25 top economics journals
\end_layout

\end_inset


\end_layout

\begin_layout Figure Notes
Replicates Figure 3 in BCH.
 The top panels presents the distribution of test statistics from the
\shape italic
 American Economic Review, Journal of Political Economy, 
\shape default
and the
\shape italic
 Quarterly Journal of Economics
\shape default
 for 
\begin_inset Formula $z\in[0,10]$
\end_inset

 over time.
 The top left panel is based on data from Brodeur et al.
 (2016).
 The bottom panels show test statistics from the Top 25 over time.
 The vertical lines indicate the the critical z-statistics at the 10%, 5%
 and 1% significance levels.
 The histograms have bin size 0.1.
 The black lines are density estimates based on a Epanechnikov kernel with
 bandwidth 0.1.
\end_layout

\end_inset

 See the online appendix for a replication of Figures 5 and 6 in BCH.
\end_layout

\begin_layout Subsection
Excess test statistics
\end_layout

\begin_layout Standard
BCH hypothesize that absent publication bias and p-hacking, the distribution
 of z-statistics would follow for each identification strategy a non-central
 t-distribution that is truncated at zero.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:excess-tests"

\end_inset

 compares these t-distributions with the empirical densities.
\begin_inset Foot
status open

\begin_layout Plain Layout
BCH showed in their Figure 4 by mistake the densities of the t-distributions
 without accounting for the truncation at zero.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:excess-tests"

\end_inset

 shows the corrected densities.
\end_layout

\end_inset

 Whether we adjust for rounding (black line) or take the original sample
 (gray line) leads visually only to small differences in the empirical kernel
 density estimates.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../Results/figure4_BCH_omission.pdf

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:dist-excess"

\end_inset


\begin_inset Formula $z$
\end_inset

-statistics by method compared to benchmark distribution
\end_layout

\end_inset


\end_layout

\begin_layout Figure Notes
Replicates Figure 4 in BCH.
 The figure compares calibrated benchmark distributions (dashed lines) with
 the observed distributions of statistics for 
\begin_inset Formula $z∈[0,10]$
\end_inset

 for each of the four idenfication methods: difference- in-differences (DID),
 instrumental variables (IV), randomized control trial (RCT), and regression
 discontinuity design (RDD).
 The black lines are BCH's observed distributions and the gray lines are
 their analogs after applying the omission approach.
 The vertical lines indicate the the critical z-statistics at the 10%, 5%
 and 1% significance levels.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement h
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../Results/excess_omit_biased-1.pdf
	scale 80

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:excess-tests"

\end_inset

Excess test statistic plots.
\end_layout

\end_inset


\end_layout

\begin_layout Figure Notes
Replicates Figure 4 in BCH.
 The dashed blue lines shows the density of BCH's originally estimated truncated
, non-central t-distribution.
 The black lines shows the empirical kernel density estimate using our adjusted
 sample and the gray line for the original sample.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Yet, there is an issue regarding the calibration of the latent distributions
 absent p-hacking and publication bias.
 BCH calibrate the degrees of freedom and non-centrality parameters of these
 t-distributions by matching the probability mass in the tails (
\begin_inset Formula $z>5$
\end_inset

) with its analog from the empirical distributions.
 They base this calibration on the assumption that the observed test statistic
 distribution above 
\begin_inset Formula $z=5$
\end_inset

 should be free of p-hacking or publication bias.
 However, even if publication bias only affects the publication probability
 for 
\begin_inset Formula $z<5$
\end_inset

, it will affect the observed probability mass in the tails, since the total
 probability mass must add up to 1.
 Correspondingly, we show in Proposition 1 in the online appendix that BCH's
 calibration approach is not able to recover the true distribution of z-statisti
cs absent publication bias, even if the correct functional form is assumed.
\begin_inset Foot
status open

\begin_layout Plain Layout
See KP for a discussion of additional issues of BCH's excess statistic approach.
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Estimating the amount of distortion
\end_layout

\begin_layout Standard
\begin_inset Float table
placement h
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:ak"

\end_inset

Relative Publication Probabilities
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
input{../Results/tab_bch_ak_drop_10.tex}
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Table Notes
This table replicates Table 5 in BCH using our rounding-adjusted data set.
 It shows the results of applying the publication bias model presented in
 Andrews and Kasy (2019).
 Note that the third coefficient in Panel B, also in BCH refers to z-statistics
 in the interval 
\begin_inset Formula $[1.96,2.33]$
\end_inset

; the label 
\begin_inset Formula $[1.96,2.58]$
\end_inset

 was a mistake.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
In addition, BCH derive the latent distributions of z-statistics without
 publication bias and p-hacking using an approach developed by Andrews and
 Kasy (2019).
 Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:ak"
plural "false"
caps "false"
noprefix "false"

\end_inset

 shows the replicated results using our adjusted data set.
 Comparing to BCH, we see that rounding has relatively little impact on
 those results.
\end_layout

\begin_layout Standard
However, the approach relies on the identifying assumption that in the latent
 distribution absent publication bias, the standard error 
\begin_inset Formula $\sigma_{i}$
\end_inset

 and estimated coefficient 
\begin_inset Formula $\mu_{i}$
\end_inset

 are independently distributed from each other.
 For a statistical test, we compute for all observations the weighted correlatio
n between 
\begin_inset Formula $\log\sigma_{i}$
\end_inset

 and 
\begin_inset Formula $\log abs(\mu_{i})$
\end_inset

 using as weights the inverse of the estimated publication probabilities.
 Under the null hypothesis that all assumptions of the chosen implementation
 of the Andrews and Kasy (2019) approach are satisfied, this inverse probability
 weighting allows to recover the correlation in the unobserved latent distributi
on of tests if no publication bias was present.
\begin_inset Foot
status open

\begin_layout Plain Layout
We thank Isaiah Andrews who proposed the idea for this inverse probability
 weighting approach and pointed out a problem of an earlier idea of ours
 to test the independence assumption.
\end_layout

\end_inset

 Table A7 in the online appendix shows the computed correlations and bootstrappe
d confidence intervals for different subsamples.
 The correlations range from 0.89 to 0.92 and the 95% confidence intervals
 from 0.88 to 0.93.
 These results suggest that the crucial independence assumption of Andrews
 and Kasy (2019) is strongly violated in BCH's data set.
\begin_inset Foot
status open

\begin_layout Plain Layout
Note that if this independence assumption held, there would be a negative
 correlation between standard errors and z-statistics and then Assumption
 1 of our adjustment approach would likely be violated.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-2"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard

\series bold
Andrews, Isaiah and Maximilian Kasy.

\series default
 2019.
 
\begin_inset Quotes eld
\end_inset

Identification of and correction for publication bias.
\begin_inset Quotes erd
\end_inset

 
\shape italic
American Economic Review
\shape default
 109 (8): 2766-94.
\end_layout

\begin_layout Standard

\series bold
Brodeur, Abel, Nikolai Cook, and Anthony Heyes.
 
\series default
2020.
 
\begin_inset Quotes eld
\end_inset

Methods Matter: p-Hacking and Publication Bias in Causal Analysis in Economics.
\begin_inset Quotes erd
\end_inset

 
\shape italic
American Economic Review
\shape default
, 110 (11): 3634-60.
\end_layout

\begin_layout Standard

\series bold
Brodeur, Abel, Mathias Lé, Marc Sangnier, and Yanos Zylberberg.

\series default
 2016.
 
\begin_inset Quotes eld
\end_inset

Star Wars: The Empirics Strike Back.
\begin_inset Quotes erd
\end_inset

 
\shape italic
American Economic Journal: Applied Economics
\shape default
, 8 (1): 1-32.
\end_layout

\begin_layout Standard

\series bold
Bruns, Stephan B, Igor Asanov, Rasmus Bode, Melanie Dunger, Christoph Funk,
 Sherif M.
 Hassan, Julia Hauschildt, et al.

\series default
 2019.
 “Errors and Biases in Reported Significance Levels: Evidence from Innovation
 Research.” 
\shape italic
Research Policy
\shape default
 48 (9): 103796.
\end_layout

\begin_layout Standard

\series bold
Kranz, Sebastian and Peter Pütz.

\series default
 2021
\change_inserted 357394701 1635910786
.

\change_unchanged
 
\begin_inset Quotes eld
\end_inset

Rounding and other pitfalls in meta-studies on p-hacking and publication
 bias: A comment on Brodeur et al.
 (2020)
\begin_inset Quotes erd
\end_inset


\change_deleted 357394701 1635910448
, working paper.
\change_inserted 357394701 1635911118
.
 SSRN working paper, available at:
\end_layout

\begin_layout Standard

\change_inserted 357394701 1635910548
https://ssrn.com/abstract=3848786.
\change_unchanged

\end_layout

\begin_layout Standard

\series bold
\begin_inset Note Note
status open

\begin_layout Plain Layout

\series bold
Pütz, Peter, and Stephan B.
 Bruns.

\series default
 2021
\change_inserted 357394701 1635910783
.

\change_unchanged
 
\begin_inset Quotes eld
\end_inset

The (Non‐) Significance Of Reporting Errors In Economics: Evidence From
 Three Top Journals.
\begin_inset Quotes erd
\end_inset

 
\shape italic
Journal of Economic Surveys
\shape default
 35.1 (2021): 348-373.
\end_layout

\end_inset


\end_layout

\end_body
\end_document
